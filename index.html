<html>
<title>Automatic Determination of Cardiac Volumes from MRI Scans</title>
<meta name="viewport" content="width=1200">
<meta charset="UTF-8">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>


<style>
<style type="text/css">


body, html {
    height: 100%;
    margin: 0;
}

.bg {
    /* The image used */
    background-image: url("bcground.png");

    /* Full height */
	
    height: 100%; 
	max-height: 1100px;
    /* Center and scale the image nicely */
    background-position: center; 
    background-repeat: no-repeat;
    background-size: cover;
}
.heading1 {
  text-align: center;
  position: absolute;
  top: 300px;
  left: 50%;
  transform: translate(-50%, -50%);
  color: white;
  font:Lato, sans-serif;
}
.span1{
display:block;
}
.body1{
  text-align: left;
  position: absolute;
  margin-left:100px;
  margin-right:100px;
  vertical-align: top;
}
.image3{
max-width:100%;
max-height:100%;
display: block;
margin-left: auto;
margin-right: auto;
}
.image2{
max-width:500px;
max-height:100%;
display: block;
margin-left: auto;
margin-right: auto;
}
a:before {
  display: block;
  content: " ";
  margin-top: -80px;
  height: 64px;
  visibility: hidden;
}
.footer {
padding:0px;
	margin-left:-0%;
   bottom: 0;
   width: 100%;
   background-color: #e6e6e6;
   color: gray;
   text-align: center;
   
}
ul {
  list-style-type: none;
}
.centr{
left:-15px;
  margin-right:auto;
  margin-left:auto;

}
</style>

<head class="container">

<nav class="navbar navbar-light navbar-fixed-top" style="background-color: white;"  >
  <div class="container-fluid">
    <div >
      <a class="navbar-brand" href="#">CSE 6242</a>
    </div>
    <ul class="nav navbar-nav" id="nav1">
	  <li class="active" ><a href="#linktotop" rel="rel1">Home</a></li>
      <li><a href="#intro" rel="rel1">Introduction</a></li>
      <li><a href="#survey" rel="rel1">Survey</a></li>
      <li><a href="#approach" rel="rel1">Approach</a></li>
      <li><a href="#results" rel="rel1">Results</a></li>
      <li><a href="#visualization" rel="rel1">Visualization</a></li>   
      <li><a href="#conclusion" rel="rel1">Conclusion</a></li>
    </ul>
  </div>

  </nav>
  <a name="linktotop"></a>
<div class="bg" name="home" width="100%">
 <div class="heading1">
			<span class="span1" width="1000px" ><p style="font-size:50px;" >Automatic Determination of Cardiac Volumes from MRI Scans</p> </span>
				<span>	<h3>Transforming Diagnosis of Heart Diseases</h3></span>
</div>
</div>



 </head>

<body>

<div class="body1">
<a name="intro"></a>
	
<br><h2>Introduction</h2>
<br><p>Diagnosing cardiac anomalies is a leading issue faced by medical researchers, and several methods have been used to estimate a heart’s “Cardiac Output”, that is, the volume of the ventricles, in both active (systolic) and resting (diastolic) states. The incentive behind doing so is to be able to effectively calculate the heart’s ejection fraction (EF), which is defined as the percentage of blood ejected from the left ventricle with each heartbeat. The ventricles’ volumes and the ejection fraction together are predictive of a number of heart diseases and hold much promise in early detection of cardiac anomalies. While multiple modalities can measure cardiac volumes and the subsequent ejection fraction, calculating them from Magnetic Resonance Imaging (MRIs) yields the best results. However, the current standard for the estimation of ventricle volumes is to have a cardiologist calculate them manually from MRIs in a rather time consuming process. Automating this process will allow doctors to diagnose heart conditions early/ better, and carries broad implications for advancing the science of heart disease treatment and therefore forms the inspiration of our project. </p>
<br><h2>Problem Definition</h2>
<br><p>Our aim is to automate the manual processing involved in determination of cardiac volumes by training a convolutional neural network(CNN) that can approximate the end-systolic/diastolic volume of the left ventricle using the same MRIs an expert would need. Our task is that of supervised regression, and the loss function used is mean square error (MSE) using convex L2 minimization.</p>

<br><h2>Dataset</h2>
<br><p>The data was sourced from the 2016 Data Science Bowl competition. The original dataset consisted of 4 channel (4ch), 2 channel (2ch) and multiple short axis (SAX) views for approximately 500 patients in the training set. 
However, the 4ch views were the most effective and usable form, as the ventricles are clearly visible in the coronal plane.<br>
Post cleaning and filtering, we have 30 4-channel MRIs each for 480 patients, thus giving us a total of 14400 training images. The validation and test sets have 4ch MRIs for approximately 200 patients each.
The images are in the DICOM (Digital Imaging and Communications in Medicine) format which also contained metadata such as age, sex, heart size for all the patients.
The data occupied  around 45 GB in total.
</p>


<a name="survey"></a>
<br><h2>Survey</h2>
<br><p>The three questions addressed by each paper are:<br>
I. Main Idea<br>
II. How’s the paper useful for our project?<br>
III. What are the shortcomings, how do we improve upon them?<br></p>

<strong>Paper- 1</strong>
<p>
I. Proposes first segmenting for the ROI and then cardiac output from MRI images as regression problem using CNNs.<br>
II. Has used the same dataset as ours.<br>
III. The combined approach for segmentation and cardiac output calculation might not work as well as a more modular approach.<br>
</p>
<strong>Paper- 2, 3, 5</strong>
<p>
I. Explores ensemble learning, SVMs and Deep-Belief-Networks to achieve our project’s aim.<br>
II. Advantages: good generalization, high accuracy for smaller amounts of training data and less variance can be incorporated.<br>
III. These papers focus on small datasets with low variance and noise. <br>
</p>
<strong>Paper- 4, 8, 11</strong>
<p>
I. Explains concepts of deep learning, tracking features across frames, active contours.<br>
II. Our project uses the concepts mentioned above.<br>
III. No shortcomings. These are seminal works, used as reference even today, post adaptation.<br>
</p>
<strong>Paper-6</strong>
<p>
I. Proposes fully automated segmentation and tracking of the myocardium that can be used for measuring regional motion, deformation, as well as labelling and tracking specific regions of the heart.<br>
II. Introduces potential transformations for segmentation of data.Also shows a way to relate images spatially and temporally.<br>
III. Is done for 4D-MRI images, which is different from our dataset and cannot be used as is.<br>
</p>
<strong>Paper-7</strong>
<p>
I. Proposes a method by which we can automatically segment the left ventricle from a 3D-MRI.<br>
II. Explains how the data might be “unclean” due to variations in factors like blood flow, partial volume-effects etc. <br>
III. Uses multi-model prior knowledge that is not applicable to our dataset.<br>
</p>
<strong>Paper-9</strong>
<p>
I. Presents a segmentation approach that is robust and accurate on the short axis cardiac MRI.<br>
II. Part of our dataset contains images that are short axis MRI images, thus making this approach important.<br>
III. The ROI needs to be remedied with certain transformations to bring the ROI in the same form as the other images. <br>
</p>
<strong>Paper-10</strong>
<p>
I. Proposes the use of a Deep-Belief-Network for detecting the ROI in the left ventricle of the heart.<br>
II. Combining active contours with a DBN results in needing smaller datasets for training.<br>
III. The method described needs manual initialization, which we avoid by using CNN.<br>
</p>
<strong>Paper-12</strong>
<p>
I. Fast and robust implementation of a CNN to perform automated ventricle segmentation.<br>
II. This model of segmentation of ventricles uses a single learning stage, and can leverage computational resources like GPUs at massive scales.<br>
III. The models were trained on the Sunnybrook dataset, which is too small to create complex, powerful models.<br>
</p>
<strong>Paper-13</strong>
<p>
I. A CNN is used for restoration of noisy or degraded images as opposed to traditional methods. Shows significant improvement in performance.<br>
II. Useful because medical images received may be noisy or degraded and hence image-segmentation may not be possible.<br>
III. Uses a feedforward network on every patch of the image hence slow. This will be solved by partially rarefying the weights[15].<br>
</p>
<strong>Paper-14</strong>
<p>
I. Two networks in a recursive training architecture are used. One generates a preliminary boundary-map and another generates the final boundary-map.<br>
II. Faster restoration of degraded images hence improving performance.<br>
III. Computationally heavy, GPU acceleration will help.<br>
</p>
<strong>Paper-15</strong>
<p>
I. Performs better than conventional statistical-shape models by utilizing random walks for segmentation.<br>
II. Useful for accurate segmentation and shows better generalization.<br>
III. The dataset doesn’t truly represent the actual data population which can be addressed by collecting more data.<br>
</p>
<strong>Paper-16</strong>
<p>
I. Trains a neural net to learn augmentation and decide which augmentations best improves the classifiers.<br>
II. Can potentially eliminate manual data-augmentation. <br>
III. The automated augmentation might not result in improving the performance of the CNN.<br>
</p>
<strong>Paper-17</strong>
<p>
I. Advocates using prior knowledge about the shape of the organ being analyzed and its location instead of only pixel-wise classifiers, when training CNNs. <br>
II. Knowledge of anatomy of heart could be used to eliminate corrupted/misleading data.<br>
III. No shortcomings.<br>
</p>
<strong>Paper-18</strong>
<p>
I. Discusses image-processing and feature-extraction techniques when using a neural network to classify images. <br>
II. Use feature-extraction and image pre-processing techniques. <br>
III. Some techniques discussed are not applicable to our dataset. <br>
</p>


<a name="approach"></a>
<br><h2>Approach taken:</h2>
<br><p>
<strong>1. Proposed Method:</strong>
<br><p>Our approach to solving the problem was to train a CNN that could potentially perform the task well enough in lieu of a trained cardiologist. In order to be able to do so, we first preprocessed the data to maximize the information that our features would be conveying to the CNN by using some traditional image processing techniques. We followed it up with the training of the CNN, and to justify the additional resources that are associated with it, we compared it to multiple other simpler, less compute and time intensive regressors.</p>
<br><p>
<strong>2. Preprocessing:</strong>
<br><p>The available data had a lot of inconsistencies such as varying sizes and orientations. Consequently, this is the task that we put most of our efforts and time in.<br>
Since we wanted to create a CNN that was computationally efficient, but at the same time did not suffer from any biases and had a good sampling of the overall distribution, we restricted our input MRIs to those which had 4 channel views as the ventricles were seen most clearly in these images. It would be a reasonable assumption that a human expert would also choose a 4ch view over a 2ch or SAX view of the heart<br>
All the input images were first resized to 256x256 pixels. The metadata was saved for later analyses. The region of interest (RoI) was near the center of the resized images and a 128x128 region around the RoI was extracted to keep only the relevant information and discard unnecessary data. The advantage of doing this is that the matrix formed after flattening and concatenating all the images will have only the relevant features, thus making the problem less underdetermined, leading to a better accuracy. This area was then resized to 64x64 to reduce computation time as smaller feature matrices reduce computation costs. Finally, a radial basis transfer function was applied on the extracted image to give a probability estimate for the final RoI in the cropped feature images. <br>
For the regression methods described in the experiments section, the (64,64) 4ch images were flattened into (1x4096) vectors. Our input would therefore be an MxN matrix:<br>
M ( #rows) = (4 ch images )*(# patients) = 30*480 = 14400<br>
N  (#columns) = 4096<br>
<div class="row">
<div class="col-md-4"><img class="image3" src="Webp.net-resizeimage (3).gif"></img><h3>1.	Original image:</h3><p>The gif shows the 4-chambered views of patient 1’s heart. The different regions that one can see here are the ventricles (which are our region of interest), the pulmonary semilunar valve and the combination of the Epicardium, Myocardium and Endocardium (together popularly called the “wall of the heart”). The “active” parts of the gif show how the volumes of the ventricles change in systole (active) and diastole (resting). Even when using the same modality, often the dimensions of an MRI are different for patients, which was a problem that we encountered when we started using this data. </p></div>
<div class="col-md-4"><img class="image3" src="Webp.net-resizeimage (2).gif"></img><h3>2.	Region of Interest:</h3><p>Our general region of interest are the two ventricles, as seen in the picture, bounded by the blue circle. Our volumes and ejection fractions are calculated for the left ventricle. As we see, we’ve zoomed into our ROI with a good degree of accuracy for an automated segmentation method. An important step to getting to our ROI was reshaping the image to a form that is standard across frames and patients. We followed it up with getting approximate centers and radii for our ROI in these images and bounding them with a circle.</p></div>
<div class="col-md-4"><img class="image3" src="Webp.net-resizeimage (1).gif"></img><h3>3.	Gaussian Probability Map:</h3><p>We ran a radial basis function across the reshaped image to get a probability map that helps us find the areas of interest as shown in the picture. This is a zoomed-out image to give us an idea of why the previous step is necessary and also showing that we can get our ROI as a probability function that then enables us to crop into our final area of interest, which is bounded in the circle in the next image.</p></div>
</div>
</p>
</p>
<p>
<strong>3. Architecture:</strong>
<br><p>Our implemented CNN was a modified, simpler version of the U-Net architecture that has found much success in biological object recognition. It will consisted of convolutional, pooling and fully connected layers. Our intermediate activation functions are Rectified Linear Units (ReLUs) and the final is a sigmoid function.
<br>Our model consisted of three convolutional layers, one flattening layer and two fully connected layers used as part of the CNN architecture. Each of three convolutional layers used a single convolved layer, max pooling, and Relu layer. The output of the third convolutional layer which was multidimensional tensor, which was converted to a one-dimensional tensor in the next layer which was the flattened layer. The output of the flattened layer was used to create the fully connected layer, which took all the inputs and used the standard z = wx + b operation on it. At the end Relu was used to add nonlinearity to it. The next layer was another fully connected layer that took the output of the last fully connected layer and performed the same operation, except this time Relu layer was not used. The output of the final layer was used as output of the CNN. Two separate convolutional neural nets used for end systolic and diastolic volume prediction. Learning rates ranging from 10-5 to 10-3, and batch sizes of 32,64,96,128 were tried, of which 10-4 ,32 worked best. The model took close to 800 epochs to converge. 
<br>The CNN optimized on the mean squared loss between the output of the last fully connected layer and the y_true data, when training. The entire architecture was implemented in TensorFlow.

</p>
<img class="image2" src="arch.png" max-width="100px"></img>
<br>
<p><strong>4. Visualization:</strong>
<br><p>We have made this website as part of our visualization. It includes an interactive scatterplot which displays the volume of LV along with the patient details sourced from the metadata available from the dicom images. We have compiled all the visualizations on a Tableau dashboard, published it on a server and have embedded it on this website.</p>
</p>

<a name="results"></a>
<br><h2>Experiments, Evaluation and Results:</h2>
<p>Our experiments ensured that the extra time and effort spent in designing and training the CNN was justified in terms of accuracy.​ Multiple toy models were implemented, thus giving us baseline estimates for different ML algorithms:
<br>
Linear Regression: The most basic regressor known to mankind, it is the most economical in terms of compute, with no parameters or hyper-parameters to tune, and is extremely simple to implement.​ It however, understandably had the lowest accuracy, but was extremely fast and simple to implement.
<br>
Support Vector Machine: Another popular ML algorithm, while SVMs aren't very quick, they provide good accuracies and when kernelized, can be extended to very high dimensions and highly non-linear mappings.
<br>
Single-layer Neural Network: We compared our program’s results against a single layer neural network’s to make sure that our approach justifies the additional time and compute required for a CNN as opposed to a vanilla neural net. The 1-layer NN acted as our baseline, minimum accuracy that we tuned the CNN to beat.
<br>
Random Forests: Random forests, which are an ensemble of different regression trees can be used for nonlinear multivariate regression. Each leaf contains a distribution for the continuous output variables. Just as with classification, random forests provide good accuracy and are fairly robust to biases in the dataset.
<br>
For the experiments, we used the standard cross-validation of 3 and worked with standard practices for hyperparameter tuning in the sklearn library. The MSE of the models were converted to accuracy percentages by using the true labels of our test data and taking its fraction.
<br></p>

<a name="visualization"></a>
<br><h2> Interactive Visualization:</h2>
<div class='tableauPlaceholder' id='viz1524591149245' style='position: relative'><noscript><a href='#'><img alt='Dashboard 1 ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;28&#47;28FPSP8QY&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='path' value='shared&#47;28FPSP8QY' /> <param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;28&#47;28FPSP8QY&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='filter' value='publish=yes' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1524591149245');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='1024px';vizElement.style.height='795px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>

<br><h2>List of Innovations:</h2>
<br><p>1. Traditional image processing techniques were used to augment the machine learning methods to maximize the information content of our features, thus improving our models’ accuracies instead of simply collecting more data and making the process extremely compute and resource heavy.
<br>2. We exploited a priori knowledge of the images to concentrate and enhance the parts of our images and reduce the effect and number of “outlier pixels” in it.
<br>3. Our CNN is a more application-specific and computationally efficient version of the U Net.
</p>
<a name="conclusion"></a>
<br><h2>Conclusion:</h2>
<p>As expected, regular L2-minimizing linear regression performs least accurately. However, it serves as a good estimate as to for a minimum, required accuracy for any model that further develops. Using L1-minimization could possibly have provided a better fit and subsequent accuracy.
We notice that the support vector regressor performs fairly well, which might imply that the data might be linearly separable once we perform a radial basis transformation. This isn’t surprising especially as we’ve used a radial basis smoothing on our input features.
Random forests perform well, as expected, while the 1-layer neural network serves as a decent starting point for the CNN to improve upon.
</p>
<br><h2>Future Work</h2>
<p>Further tuning of the hyperparameters will definitely improve the CNN’s accuracy, and is one of the most promising directions for future work.
Another improvement would be to increase the number of layers and making the network deeper. This would introduce the possibility of bad generalization and overfitting, which could be combated with regularization techniques like drop-out, or techniques like early stopping. </p>

<br><h2>References</h2>
<p>
<br>[1] Estimating the volume of the left ventricle from MRI images using deep neural networks. Journal of Latex class files, Vol.14, No.8, August 2015. Fangzhou Liao, Xi Chen, Xiaolin Hu, Senior Member, IEEE and Sen Song

<br><br>[2] Diagnosing Coronary Heart Disease Using Ensemble Machine Learning.(IJACSA) International Journal of Advanced Computer Science and Applications, Vol. 7, No. 10, 2016. Kathleen H. Miao , Julia H. Miao , and George J. Miao.


<br><br>[3] Applying Machine Learning Methods in Diagnosing Heart Disease for Diabetic Patients. International Journal of Applied Information Systems (IJAIS) – ISSN : 2249-0868  Volume 3– No.7, August 2012. G. Parthiban and S.K.Srivatsa

<br><br>[4] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” Nature, vol. 521, no. 7553, pp. 436–444, May 2015.

<br><br>[5] T. A. Ngo and G. Carneiro, “Left ventricle segmentation from cardiac MRI combining level set methods with deep belief networks,” in Proceedings of International Conference on Image Processing, Sep. 2013, pp. 695–699.

<br><br>[6] M. Lorenzo-Valds, G. I. Sanchez-Ortiz, R. Mohiaddin, and D. Rueckert, “Atlas-Based Segmentation and Tracking of 3D Cardiac MR Images Using Non-rigid Registration,” in Proceedings of International Conference on Medical Image Computing and Computer Assisted Intervention. Springer Berlin Heidelberg, Sep. 2002, pp. 642–650.

<br><br>[7] M. R. Kaus, J. von Berg, J. Weese, W. Niessen, and V. Pekar, “Automated segmentation of the left ventricle in cardiac MRI,” Medical Image Analysis, vol. 8, no. 3,
pp. 245–254, 2004.

<br><br>[8]P. Viola and M. Jones, “Rapid object detection using a boosted cascade of simple features,” in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, vol. 1. IEEE, 2001, pp. I–511.

<br><br>[9]H. Hu, H. Liu, Z. Gao, and L. Huang, “Hybrid segmentation of left ventricle in cardiac MRI using gaussian mixture model and region restricted dynamic programming,” Magnetic Resonance Imaging, vol. 31, no. 4, pp. 575–584, May 2013.

<br><br>[10]T. A. Ngo, Z. Lu, and G. Carneiro, “Combining deep learning and level set for the automated segmentation of the left ventricle of the heart from cardiac cine magnetic resonance,” Medical Image Analysis, vol. 35, pp. 159–171, Jan. 2017.

<br><br>[11] M. Kass, A. Witkin, and D. Terzopoulos, “Snakes: Active contour models,” International Journal of Computer Vision, vol. 1, no. 4, pp. 321–331, 1987.

<br><br>[12] P. V. Tran, “A Fully Convolutional Neural Network for Cardiac Segmentation in Short-Axis MRI,” arXiv:1604.00494 [cs], Apr. 2016.

<br><br>[13] V. Jain, J. F. Murray, F. Roth, S. Turaga, V. Zhigulin, K. L. Briggman, M. N. Helmstaedter, W. Denk, and H. S. Seung, “Supervised Learning of Image Restoration with Convolutional Networks,” in Proceedings of IEEE International Conference on Computer Vision, Oct. 2007, pp. 1 – 8.

<br><br>[14] K. Lee, A. Zlateski, V. Ashwin, and H. S. Seung, “Recursive Training of 2D-3D Convolutional Networks for Neuronal Boundary Prediction,” in Advances in Neural Information Processing Systems, 2015, pp. 3573–3581.

<br><br>[15] A. Eslami, A. Karamalis, A. Katouzian, and N. Navab, “Segmentation by retrieval with guided random walks: Application to left ventricle segmentation in MRI,” Medical Image Analysis, vol. 17, no. 2, pp. 236–253, Feb. 2013.


<br><br>[16] Jason Wang, Luis Perez, “The Effectiveness of Data Augmentation in Image Classification using Deep Learning”, ArXiv e-prints, Dec. 2017. 

<br><br>[17] Ozan Oktay, Enzo Ferrante, Konstantinos Kamnitsas, Mattias Heinrich, Wenjia Bai, Jose Caballero, Stuart Cook,  Antonio de Marvao, Timothy Dawes, Declan O’Regan, Bernhard Kainz, Ben Glocker, and Daniel Rueckert, “Anatomically Constrained Neural Networks (ACNN): Application to Cardiac Image Enhancement and Segmentation”, IEEE Transactions on Medical Imaging, AUG 2017. 


<br><br>[18] Elalfi A., Eisa M. and Ahmed H, “Artificial neural networks in medical images for diagnosis heart valve diseases”, International. Journal of computer science issues, 2013.

</p>


<div class="footer row">
<div class="col-md-6" ><p class="text-muted"><br><br><br>Built for CSE 6242: Data and Visual Analytics<br>Georgia Tech, College of Engineering<br><br><br></p></div>
<div class="col-md-6 centr" ><p class="text-muted centr">
<ul>
<strong>Team Members: </strong>
<li>Aishwarya Balwani</li>
<li>Aditya Chavan</li>
<li>Sapan Desai</li>
<li>Parth Desai</li>
<li>Bhakti Patel</li>
<li>Vishwateja Reddy</li>
</ul>

</p></div>

</div>
     

<script type="text/javascript">
// Select all links with hashes
$('a[href*="#"]')
  // Remove links that don't actually link to anything
  .not('[href="#"]')
  .not('[href="#0"]')
  .click(function(event) {
    // On-page links
    if (
      location.pathname.replace(/^\//, '') == this.pathname.replace(/^\//, '') 
      && 
      location.hostname == this.hostname
    ) {
      // Figure out element to scroll to
      var target = $(this.hash);
      target = target.length ? target : $('[name=' + this.hash.slice(1) + ']');
      // Does a scroll target exist?
      if (target.length) {
        // Only prevent default if animation is actually gonna happen
        event.preventDefault();
        $('html, body').animate({
          scrollTop: target.offset().top
        }, 800, function() {
          // Callback after animation
          // Must change focus!
          var $target = $(target);
          if ($target.is(":focus")) { // Checking if the target was focused
            return false;
          } else {
            $target.attr('tabindex','-1'); // Adding tabindex for elements not focusable
             };
        });
      }
    }
  });
</script>

</body>


	
	
</html>
